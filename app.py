import streamlit as st
from auth import AuthSystem
from datetime import datetime, timedelta
import pytz
import os
import glob
import logging

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('/tmp/app.log'),
        logging.StreamHandler()
    ]
)

def show_logo():
    col1, col2, col3 = st.columns([1, 2, 1])
    with col2:
        try:
            st.image("legallexmvplogo.png", width=150)
        except:
            st.markdown("## ‚öñÔ∏è LegalLex")

def admin_page():
    logging.info("Admin page accessed")
    show_logo()
    st.title("üì§ Upload An√°lises Inteligentes")
    st.markdown("---")
    
    # Logout button
    if st.button("üö™ Sair", key="admin_logout"):
        AuthSystem.logout()
    
    st.markdown("### Enviar An√°lises Inteligentes")
    st.markdown("Fa√ßa upload de arquivos HTML com an√°lises jur√≠dicas que ser√£o disponibilizadas aos clientes.")
    
    uploaded_files = st.file_uploader(
        "Selecione os arquivos HTML",
        type=['html'],
        accept_multiple_files=True,
        key="analysis_upload"
    )
    
    if uploaded_files:
        if st.button("üì§ Enviar An√°lises", type="primary"):
            saved_count = 0
            
            # Create analyses directory if it doesn't exist
            os.makedirs("analyses", exist_ok=True)
            
            for uploaded_file in uploaded_files:
                try:
                    # Generate unique filename with timestamp
                    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                    original_name = uploaded_file.name.replace('.html', '')
                    filename = f"analyses/{timestamp}_{original_name}.html"
                    
                    # Save file
                    with open(filename, 'wb') as f:
                        f.write(uploaded_file.getbuffer())
                    
                    logging.info(f"Analysis file uploaded: {filename}")
                    saved_count += 1
                except Exception as e:
                    logging.error(f"Error uploading file {uploaded_file.name}: {str(e)}")
                    st.error(f"Erro ao enviar {uploaded_file.name}: {str(e)}")
            
            st.success(f"‚úÖ {saved_count} an√°lise(s) enviada(s) com sucesso!")
    
    # Show existing analyses count and management
    existing_analyses = sorted(glob.glob("analyses/*.html"), key=os.path.getmtime, reverse=True)
    st.info(f"üìä Total de an√°lises dispon√≠veis: {len(existing_analyses)}")
    
    # Analysis management section
    if existing_analyses:
        st.markdown("### üóÇÔ∏è Gerenciar An√°lises Existentes")
        
        # Show list of analyses with delete buttons
        for analysis_path in existing_analyses[:10]:  # Show only latest 10
            filename = os.path.basename(analysis_path)
            readable_name = filename.replace('.html', '').replace('_', ' - ', 1)
            mod_time = datetime.fromtimestamp(os.path.getmtime(analysis_path))
            
            col1, col2 = st.columns([4, 1])
            with col1:
                st.markdown(f"**{readable_name}**")
                st.markdown(f"*Criado: {mod_time.strftime('%d/%m/%Y √†s %H:%M')}*")
            
            with col2:
                if st.button("üóëÔ∏è Deletar", key=f"delete_{filename}"):
                    try:
                        os.remove(analysis_path)
                        logging.info(f"Analysis file deleted: {analysis_path}")
                        st.success(f"‚úÖ Arquivo deletado: {readable_name}")
                        st.rerun()
                    except Exception as e:
                        logging.error(f"Error deleting file {analysis_path}: {str(e)}")
                        st.error(f"‚ùå Erro ao deletar arquivo: {str(e)}")
            
            st.markdown("---")
        
        # Show total count if more than 10
        if len(existing_analyses) > 10:
            st.info(f"Mostrando 10 de {len(existing_analyses)} an√°lises. Os demais podem ser gerenciados via sistema de arquivos.")

def client_dashboard():
    logging.info("Client dashboard accessed")
    # Logo in sidebar (centered)
    with st.sidebar:
        col1, col2, col3 = st.columns([1, 2, 1])
        with col2:
            try:
                st.image("legallexmvplogo.png", width=100)
            except Exception as e:
                logging.warning(f"Logo not found: {str(e)}")
                st.markdown("### ‚öñÔ∏è LegalLex")
    
    # Navigation
    st.sidebar.title("üß≠ Navega√ß√£o")
    
    # Logout button in sidebar
    if st.sidebar.button("üö™ Sair"):
        AuthSystem.logout()
    
    page = st.sidebar.radio(
        "Selecione uma p√°gina:",
        ["‚öôÔ∏è Configurar Regras", "üìã Resultados Di√°rios", "üîç An√°lises Inteligentes"]
    )
    
    logging.info(f"Client navigated to page: {page}")
    
    if page == "‚öôÔ∏è Configurar Regras":
        show_rules_config()
    elif page == "üìã Resultados Di√°rios":
        show_daily_results()
    else:
        show_analyses_page()

def show_rules_config():
    st.title("‚öôÔ∏è Configura√ß√£o de Regras Autom√°ticas")
    st.markdown("---")
    
    # Show next execution time
    brasilia_tz = pytz.timezone('America/Sao_Paulo')
    tomorrow_6am = datetime.now(brasilia_tz).replace(hour=6, minute=0, second=0, microsecond=0) + timedelta(days=1)
    
    st.info(f"‚è∞ **Pr√≥xima execu√ß√£o autom√°tica:** {tomorrow_6am.strftime('%d/%m/%Y √†s %H:%M')} (Bras√≠lia)")
    st.markdown("As regras configuradas abaixo ser√£o executadas automaticamente todos os dias √†s 6:00 da manh√£.")
    
    # Import the rule configuration from the original system
    from djesearchapp import create_rule_form, SearchRule, ExclusionRule
    
    # Initialize session state for rules with hardcoded defaults
    if 'auto_rules' not in st.session_state:
        # Create default hardcoded rules
        from djesearchapp import SearchRule
        
        default_rules = [
            SearchRule(
                name="OAB Principal",
                enabled=True,
                parameters={
                    'numeroOab': '8773', 
                    'ufOab': 'ES',
                    'dataDisponibilizacaoInicio': datetime.now().strftime('%Y-%m-%d')
                }
            ),
            SearchRule(
                name="Darwin",
                enabled=True,
                parameters={
                    'nomeParte': 'Darwin', 
                    'siglaOrgaoJulgador': 'TJES',
                    'dataDisponibilizacaoInicio': datetime.now().strftime('%Y-%m-%d')
                }
            ),
            SearchRule(
                name="Sinales",
                enabled=True,
                parameters={
                    'nomeParte': 'SINALES SINALIZA√á√ÉO ESP√çRITO SANTO LTDA',
                    'dataDisponibilizacaoInicio': datetime.now().strftime('%Y-%m-%d')
                },
                exclusions=[
                    ExclusionRule(
                        name="Excluir OAB 014072 ES",
                        field="numeroOab",
                        value="014072",
                        enabled=True
                    )
                ]
            ),
            SearchRule(
                name="Multivix",
                enabled=True,
                parameters={
                    'nomeParte': 'Multivix',
                    'dataDisponibilizacaoInicio': datetime.now().strftime('%Y-%m-%d')
                }
            ),
            SearchRule(
                name="CENTRO UNIVERSIT√ÅRIO CLARETIANO",
                enabled=True,
                parameters={
                    'nomeParte': 'Claretiano',
                    'dataDisponibilizacaoInicio': datetime.now().strftime('%Y-%m-%d')
                }
            )
        ]
        
        # Load additional saved rules from file and append them
        try:
            from cronjob_scheduler import CronJobScheduler
            scheduler = CronJobScheduler()
            saved_custom_rules = scheduler.load_saved_rules()
            # Combine default rules with any custom saved rules
            all_rules = default_rules + saved_custom_rules
            st.session_state.auto_rules = all_rules
            logging.info(f"Loaded {len(default_rules)} default rules + {len(saved_custom_rules)} custom rules")
        except Exception as e:
            logging.warning(f"Could not load custom rules, using defaults only: {str(e)}")
            st.session_state.auto_rules = default_rules
    
    # Rule management buttons
    col1, col2, col3 = st.columns(3)
    with col1:
        if st.button("‚ûï Adicionar Regra"):
            st.session_state.auto_rules.append(None)
            st.rerun()
    
    with col2:
        if st.button("üóëÔ∏è Limpar Regras"):
            st.session_state.auto_rules = []
            st.rerun()
    
    with col3:
        if st.button("üíæ Salvar Regras"):
            # Save rules using CronJobScheduler
            try:
                from cronjob_scheduler import CronJobScheduler
                scheduler = CronJobScheduler()
                
                # Get configured rules from session state
                rules_to_save = []
                for i in range(len(st.session_state.auto_rules)):
                    rule = st.session_state.auto_rules[i]
                    if rule:  # Only save non-None rules
                        rules_to_save.append(rule)
                
                # Save rules to file
                scheduler.save_rules(rules_to_save)
                
                logging.info(f"Successfully saved {len(rules_to_save)} rules to file")
                st.success(f"‚úÖ {len(rules_to_save)} regra(s) salva(s)! Ser√£o executadas automaticamente √†s 6:00 da manh√£.")
                
            except Exception as e:
                logging.error(f"Error saving rules: {str(e)}")
                st.error(f"‚ùå Erro ao salvar regras: {str(e)}")
    
    # Rule configuration forms
    configured_rules = []
    for i in range(len(st.session_state.auto_rules)):
        existing_rule = st.session_state.auto_rules[i]
        rule = create_rule_form(i, existing_rule)
        if rule:
            configured_rules.append(rule)
    
    # Update rules in session state
    st.session_state.auto_rules = configured_rules
    
    # Display rule summary
    if configured_rules:
        st.markdown("## üìã Resumo das Regras Configuradas")
        for rule in configured_rules:
            status = "‚úÖ Ativa" if rule.enabled else "‚ùå Inativa"
            params_text = []
            for key, value in rule.parameters.items():
                if key != '_rule_name':
                    params_text.append(f"{key}: {value}")
            
            st.markdown(f"""
            <div style="border: 1px solid #ddd; border-radius: 8px; padding: 15px; margin: 10px 0; background-color: #f9f9f9; border-left: 4px solid #28a745;">
                <strong>{rule.name}</strong> - {status}<br>
                <small>Par√¢metros: {', '.join(params_text) if params_text else 'Nenhum'}</small><br>
                <small>Exclus√µes: {len(rule.exclusions) if hasattr(rule, 'exclusions') and rule.exclusions else 0}</small>
            </div>
            """, unsafe_allow_html=True)

def show_daily_results():
    st.title("üìã Resultados das Buscas Autom√°ticas")
    st.markdown("---")
    
    st.info("üìÖ Esta p√°gina mostra os resultados das buscas executadas automaticamente √†s 6:00 da manh√£ baseadas nas suas regras configuradas.")
    
    # Date selector for viewing results
    selected_date = st.date_input(
        "Selecione a data dos resultados:",
        value=datetime.now().date()
    )
    
    # Mock results for now - in production this would load from database
    st.markdown(f"### Resultados de {selected_date.strftime('%d/%m/%Y')}")
    
    # Check if we have stored results for this date
    publications = None
    
    # First, try to load from database for the selected date
    try:
        from database import DatabaseManager
        
        db = DatabaseManager()
        date_str = selected_date.strftime('%d/%m/%Y')
        
        # Get publications from database
        publications = db.get_publications_by_date(date_str)
        if publications:
            logging.info(f"Loaded {len(publications)} publications from database for {date_str}")
            
    except Exception as e:
        logging.error(f"Error loading results from database for {selected_date}: {str(e)}")
    
    # Fallback to session state if no file found and date matches today
    if not publications and 'last_auto_search_results' in st.session_state and 'last_search_date' in st.session_state:
        if st.session_state.last_search_date.date() == selected_date:
            publications = st.session_state.last_auto_search_results
            logging.info(f"Using session state results for {selected_date}")
    
    # If we have publications, display them
    if publications:
        from djesearchapp import display_publication_card
        import math
        
        # Pagination
        items_per_page = 10
        total_items = len(publications)
        total_pages = math.ceil(total_items / items_per_page) if total_items > 0 else 1
        
        if total_pages > 1:
            col1, col2, col3 = st.columns([1, 2, 1])
            with col2:
                page = st.selectbox("P√°gina", range(1, total_pages + 1))
        else:
            page = 1
        
        start_idx = (page - 1) * items_per_page
        end_idx = start_idx + items_per_page
        current_items = publications[start_idx:end_idx]
        
        st.info(f"üìä Mostrando {len(current_items)} de {total_items} publica√ß√µes encontradas")
        
        for i, pub in enumerate(current_items):
            display_publication_card(pub, start_idx + i)
        
        # Excel download button
        st.markdown("---")
        st.markdown("## üìä Exportar Resultados")
        if st.button("üìã Baixar em Excel"):
            try:
                import pandas as pd
                from io import BytesIO
                
                # Prepare data for Excel
                excel_data = []
                for pub in publications:
                    # Extract destinatarios (nome and polo are inside destinatarios array)
                    destinatarios = pub.get('destinatarios', [])
                    destinatarios_text = '; '.join([
                        f"{dest.get('nome', '')} ({dest.get('polo', '')})" 
                        for dest in destinatarios
                    ]) if destinatarios else ''
                    
                    # Extract advogados
                    advogados = pub.get('destinatarioadvogados', [])
                    advogados_text = '; '.join([
                        f"{adv.get('advogado', {}).get('nome', '')} - OAB {adv.get('advogado', {}).get('numero_oab', '')} {adv.get('advogado', {}).get('uf_oab', '')}"
                        for adv in advogados
                    ]) if advogados else ''
                    
                    # Extract correct fields for Excel - each publica√ß√£o becomes one row
                    row = {
                        'data_disponibilizacao': pub.get('data_disponibilizacao', ''),
                        'sigla_tribunal': pub.get('siglaTribunal', ''),
                        'tipo_comunicacao': pub.get('tipoComunicacao', ''),
                        'nome_orgao': pub.get('nomeOrgao', ''),
                        'texto': pub.get('texto', ''),
                        'numero_processo': pub.get('numeroprocessocommascara', ''),
                        'numero_processo_simples': pub.get('numero_processo', ''),
                        'meio': pub.get('meio', ''),
                        'link': pub.get('link', ''),
                        'tipo_documento': pub.get('tipoDocumento', ''),
                        'nome_classe': pub.get('nomeClasse', ''),
                        'codigo_classe': pub.get('codigoClasse', ''),
                        'destinatarios': destinatarios_text,
                        'advogados': advogados_text,
                        'hash': pub.get('hash', ''),
                        'data_disponibilizacao_alt': pub.get('datadisponibilizacao', ''),
                        'fonte_regra': pub.get('_source_rule', '')
                    }
                    excel_data.append(row)
                
                # Create DataFrame
                df = pd.DataFrame(excel_data)
                
                # Create Excel file in memory
                output = BytesIO()
                with pd.ExcelWriter(output, engine='openpyxl') as writer:
                    df.to_excel(writer, index=False, sheet_name='Publica√ß√µes')
                
                # Get the Excel data
                excel_bytes = output.getvalue()
                
                # Generate filename with date
                brasilia_tz = pytz.timezone('America/Sao_Paulo')
                date_str = selected_date.strftime('%d-%m-%Y')
                filename = f"Busca_do_dia_{date_str}.xlsx"
                
                st.download_button(
                    label="üíæ Download Excel",
                    data=excel_bytes,
                    file_name=filename,
                    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                    key="download_excel"
                )
                
            except Exception as e:
                logging.error(f"Error creating Excel file: {str(e)}")
                st.error(f"‚ùå Erro ao criar arquivo Excel: {str(e)}")
        else:
            st.warning("‚ö†Ô∏è Nenhum resultado encontrado para esta data.")
    else:
        st.warning("‚ö†Ô∏è Nenhum resultado encontrado para esta data.")
    
    # Debug database info
    try:
        from database import DatabaseManager
        db = DatabaseManager()
        search_history = db.get_search_history(limit=10)
        if search_history:
            st.info(f"üìä Database conectada! √öltimas {len(search_history)} buscas encontradas.")
            with st.expander("Ver hist√≥rico de buscas"):
                for search in search_history:
                    st.write(f"‚Ä¢ {search['name']} - {search['date']} ({search['publications_found']} publica√ß√µes)")
        else:
            st.warning("‚ö†Ô∏è Database conectada mas nenhuma busca encontrada.")
    except Exception as e:
        st.error(f"‚ùå Erro na database: {str(e)}")
        logging.error(f"Database debug error: {str(e)}")

    # Manual execution button (for testing)
    if st.button("üîç Executar Busca Manual (Teste)", type="secondary"):
        if 'auto_rules' in st.session_state and st.session_state.auto_rules:
            from djesearchapp import OptimizedDJESearcher
            
            searcher = OptimizedDJESearcher()
            progress_bar = st.progress(0)
            status_text = st.empty()
            
            def update_progress(message):
                status_text.markdown(f'üîç {message}')
            
            try:
                logging.info(f"Manual search started with {len(st.session_state.auto_rules)} rules")
                publications, stats = searcher.execute_rules(st.session_state.auto_rules, update_progress)
                progress_bar.progress(100)
                status_text.success(f"‚úÖ Busca conclu√≠da! {len(publications)} publica√ß√µes encontradas.")
                
                logging.info(f"Manual search completed: {len(publications)} publications found, stats: {stats}")
                
                # Store results in session state
                st.session_state.last_auto_search_results = publications
                st.session_state.last_search_date = datetime.now()
                
                # Save results to database
                try:
                    from database import DatabaseManager
                    
                    # Create database manager instance
                    db = DatabaseManager()
                    
                    # Create filename with today's date
                    brasilia_tz = pytz.timezone('America/Sao_Paulo')
                    brasilia_now = datetime.now(brasilia_tz)
                    date_str = brasilia_now.strftime('%d/%m/%Y')
                    filename = f"Busca do dia {date_str}"
                    
                    # Save to database
                    search_execution_id = db.save_search_execution(
                        name=filename,
                        date=date_str,
                        timestamp=brasilia_now,
                        rules_executed=len(st.session_state.auto_rules),
                        publications=publications,
                        stats=stats
                    )
                    
                    logging.info(f"Manual search results saved to database with ID {search_execution_id}")
                    status_text.success(f"‚úÖ Busca conclu√≠da e salva como '{filename}'! {len(publications)} publica√ß√µes encontradas.")
                    
                    # Debug: verify it was saved
                    verify_pubs = db.get_publications_by_date(date_str)
                    st.info(f"üîç Debug: Verifica√ß√£o - {len(verify_pubs)} publica√ß√µes salvas para {date_str}")
                    
                except Exception as e:
                    logging.error(f"Error saving manual search results to database: {str(e)}")
                    # Don't show error to user, just log it
                
                st.rerun()
                
            except Exception as e:
                logging.error(f"Error during manual search: {str(e)}")
                st.error(f"‚ùå Erro durante a busca: {str(e)}")
        else:
            st.warning("‚ö†Ô∏è Configure as regras primeiro na p√°gina 'Configurar Regras'.")

def show_analyses_page():
    st.title("üîç An√°lises Inteligentes")
    st.markdown("---")
    
    st.markdown("### An√°lises Jur√≠dicas Especializadas")
    st.markdown("Aqui voc√™ encontra an√°lises detalhadas por IA dos casos jur√≠dicos de Educa√ß√£o (Configurado pelo Darwin e Multivix), Ser√° automaticamente renovada diariamente as 06 da manh√£.")
    
    # Get all analysis files
    analysis_files = sorted(glob.glob("analyses/*.html"), key=os.path.getmtime, reverse=True)
    
    if not analysis_files:
        st.info("üìÑ Nenhuma an√°lise dispon√≠vel no momento. Novas an√°lises s√£o adicionadas diariamente.")
        return
    
    # Pagination
    items_per_page = 10
    total_items = len(analysis_files)
    total_pages = (total_items + items_per_page - 1) // items_per_page
    
    if total_pages > 1:
        col1, col2, col3 = st.columns([1, 2, 1])
        with col2:
            page = st.selectbox("P√°gina", range(1, total_pages + 1), key="analyses_page")
    else:
        page = 1
    
    start_idx = (page - 1) * items_per_page
    end_idx = min(start_idx + items_per_page, total_items)
    current_files = analysis_files[start_idx:end_idx]
    
    st.info(f"üìä Mostrando {len(current_files)} de {total_items} an√°lises (P√°gina {page} de {total_pages})")
    
    # Display analyses
    for i, file_path in enumerate(current_files):
        filename = os.path.basename(file_path)
        # Extract readable name from filename
        readable_name = filename.replace('.html', '').replace('_', ' - ', 1)
        
        # Get file modification time
        mod_time = datetime.fromtimestamp(os.path.getmtime(file_path))
        
        with st.expander(f"üìÑ {readable_name}", expanded=False):
            st.markdown(f"**Data:** {mod_time.strftime('%d/%m/%Y √†s %H:%M')}")
            
            # Read and display HTML content
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    html_content = f.read()
                
                # Display HTML content in an iframe-like container
                st.components.v1.html(html_content, height=600, scrolling=True)
                
            except Exception as e:
                st.error(f"Erro ao carregar an√°lise: {str(e)}")

def main():
    try:
        logging.info("Application started")
        
        # Check authentication first
        if not AuthSystem.check_authentication():
            logging.info("User not authenticated, showing login page")
            return
        
        # Get current user
        user = AuthSystem.get_current_user()
        logging.info(f"User authenticated: {user['username']} with role: {user['role']}")
        
        if user["role"] == "admin":
            admin_page()
        else:  # client
            client_dashboard()
            
    except Exception as e:
        logging.error(f"Critical error in main application: {str(e)}")
        st.error(f"‚ùå Erro cr√≠tico na aplica√ß√£o: {str(e)}")
        st.info("Por favor, recarregue a p√°gina ou contate o suporte.")

if __name__ == "__main__":
    main()